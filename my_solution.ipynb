{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import lightgbm as lgb\n",
    "from lightgbm import Dataset, LGBMRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBRegressor, DMatrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('https://raw.githubusercontent.com/a-milenkin/Competitive_Data_Science/main/data/quickstart_train.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/a-milenkin/Competitive_Data_Science/main/data/quickstart_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [] #for saving results for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(algorithm,\n",
    "                X,\n",
    "                y,\n",
    "                early_stopping_rounds,\n",
    "                init_params = None,\n",
    "                cat_features = None,\n",
    "                random_seed = 2023\n",
    "                ):\n",
    "    \n",
    "    scores = []\n",
    "    models = []\n",
    "\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "\n",
    "    print(f'=========Training algorithm is {algorithm.__name__}=============')\n",
    "\n",
    "    for num_fold, (train_idx,val_idx) in  enumerate(kf.split(X)):\n",
    "        X_train, X_eval = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_eval = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        if init_params is not None:\n",
    "            model = algorithm(**init_params)\n",
    "        else:\n",
    "            model = algorithm()\n",
    "        \n",
    "        if algorithm.__name__ == 'CatBoostRegressor':\n",
    "            train_dataset = Pool(X_train, y_train, cat_features=cat_features)  \n",
    "            eval_dataset = Pool(X_eval, y_eval, cat_features=cat_features)\n",
    "\n",
    "            model.fit(train_dataset,\n",
    "                      eval_set=eval_dataset,\n",
    "                      verbose=0,\n",
    "                      early_stopping_rounds=early_stopping_rounds)\n",
    "        \n",
    "        elif algorithm.__name__ == 'LGBMRegressor':\n",
    "            train_dataset = Dataset(X_train, y_train)\n",
    "            eval_dataset = Dataset(X_eval, y_eval)\n",
    "\n",
    "            model = lgb.train(params=init_params,\n",
    "                              train_set=train_dataset,\n",
    "                              valid_sets=(eval_dataset),\n",
    "                              categorical_feature=cat_features,\n",
    "                              )\n",
    "            \n",
    "        elif algorithm.__name__ == 'XGBRegressor':\n",
    "\n",
    "            train_dataset = DMatrix(X_train, y_train)\n",
    "            eval_dataset = DMatrix(X_eval, y_eval)\n",
    "\n",
    "            model = xgb.train(params=init_params,\n",
    "                              dtrain = train_dataset,\n",
    "                              evals = [(train_dataset, 'dtrain'), (eval_dataset, 'dtest')],\n",
    "                              verbose_eval = False,\n",
    "                              early_stopping_rounds = early_stopping_rounds)\n",
    "            \n",
    "\n",
    "        # Сделайте предсказание на X_eval и посчитайте RMSE\n",
    "        y_pred = model.predict(eval_dataset)\n",
    "        score = np.sqrt(mean_squared_error(y_pred, y_eval))\n",
    "\n",
    "        models.append(model)\n",
    "        scores.append(score)\n",
    "\n",
    "        print(f'Fold {num_fold} : Score {score}')\n",
    "    \n",
    "    mean_kfold_score = np.mean(scores) - np.std(scores)\n",
    "    print('Mean RSME Score', mean_kfold_score)\n",
    "\n",
    "    best_model = models[np.argmin(scores)]\n",
    "\n",
    "    return mean_kfold_score, best_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_hyperparams(algorithm,\n",
    "                       X,\n",
    "                       y,\n",
    "                       init_params,\n",
    "                       fit_params,\n",
    "                       grid_params,\n",
    "                       n_iter,\n",
    "                       cv=3,\n",
    "                       random_state=2023):\n",
    "    \n",
    "    estimator = algorithm(**init_params)\n",
    "\n",
    "    model = RandomizedSearchCV(estimator=estimator,\n",
    "                               param_distributions=grid_params,\n",
    "                               n_iter=n_iter,\n",
    "                               cv=cv,\n",
    "                               scoring='neg_root_mean_squared_error',\n",
    "                               n_jobs=-1,\n",
    "                               verbose=0,\n",
    "                               random_state=random_state)\n",
    "    \n",
    "    model.fit(X, y, **fit_params)\n",
    "\n",
    "    return init_params | model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered_features: ['model', 'car_type', 'fuel_type', 'car_rating', 'year_to_start', 'riders', 'year_to_work', 'target_reg', 'mean_rating', 'distance_sum', 'rating_min', 'speed_max', 'user_ride_quality_median', 'deviation_normal_count', 'user_uniq']\n",
      "num_features: ['car_rating', 'year_to_start', 'riders', 'year_to_work', 'target_reg', 'mean_rating', 'distance_sum', 'rating_min', 'speed_max', 'user_ride_quality_median', 'deviation_normal_count', 'user_uniq']\n",
      "cat_features: ['model', 'car_type', 'fuel_type']\n"
     ]
    }
   ],
   "source": [
    "target = ['target_reg']\n",
    "features2drop = ['car_id','target_class']\n",
    "columns_to_drop = target + features2drop \n",
    "cat_features =  train.drop(columns=columns_to_drop).select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "\n",
    "filtered_features = [i for i in train.columns if (i not in features2drop)]\n",
    "num_features = [i for i in filtered_features if (i not in cat_features)]\n",
    "\n",
    "print(f'filtered_features: {filtered_features}')\n",
    "print(f'num_features: {num_features}')\n",
    "print(f'cat_features: {cat_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered features after drop: ['model', 'car_type', 'fuel_type', 'car_rating', 'year_to_start', 'riders', 'year_to_work', 'target_reg', 'mean_rating', 'distance_sum', 'rating_min', 'speed_max', 'user_ride_quality_median', 'deviation_normal_count', 'user_uniq']\n"
     ]
    }
   ],
   "source": [
    "X = train[filtered_features].drop(target, axis=1, errors=\"ignore\")\n",
    "y = train[target]\n",
    "print(f\"Filtered features after drop: {filtered_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Training algorithm is CatBoostRegressor=============\n",
      "Fold 0 : Score 11.926355935511776\n",
      "Fold 1 : Score 11.882241144706034\n",
      "Fold 2 : Score 11.36731068554355\n",
      "Mean RSME Score 11.471524232962208\n"
     ]
    }
   ],
   "source": [
    "cb_init_params = {\n",
    "    'loss_function': 'RMSE',\n",
    "    'eval_metric': 'RMSE',\n",
    "    'thread_count': -1,\n",
    "    'task_type': 'CPU',\n",
    "    'random_seed': RANDOM_STATE\n",
    "}\n",
    "\n",
    "cb_score, cb_model = train_model(\n",
    "    algorithm=CatBoostRegressor,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    init_params=cb_init_params,\n",
    "    early_stopping_rounds=50,\n",
    "    random_seed=RANDOM_STATE,\n",
    "    cat_features=cat_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_features_for_test = [feature for feature in filtered_features if feature != 'target_reg']\n",
    "X_test = test[filtered_features_for_test]\n",
    "cb_test_pred = cb_model.predict(X_test)\n",
    "pd.DataFrame({'car_id': test['car_id'], 'target_reg': cb_test_pred}).to_csv('cb_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\n",
    "    'model_name': 'CatBoostRegressor',\n",
    "    'tuning': False,\n",
    "    'kfold_score': cb_score,\n",
    "    'leaderboard_score': 'RMSE=11.9',\n",
    "    'model': cb_model\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "сb_fit_params  = {\n",
    "    'cat_features': cat_features,\n",
    "    'verbose': 0,\n",
    "    'early_stopping_rounds': 50}\n",
    "\n",
    "cb_grid_params = {\n",
    "    'depth': [4, 6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'l2_leaf_reg': [1, 3, 5],\n",
    "    'iterations': [500, 1000],\n",
    "    'rsm': [0.8, 0.9, 1.0],\n",
    "    'border_count': [32, 64, 128]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_function': 'RMSE',\n",
       " 'eval_metric': 'RMSE',\n",
       " 'thread_count': -1,\n",
       " 'task_type': 'CPU',\n",
       " 'random_seed': 42,\n",
       " 'rsm': 1.0,\n",
       " 'learning_rate': 0.01,\n",
       " 'l2_leaf_reg': 3,\n",
       " 'iterations': 1000,\n",
       " 'depth': 8,\n",
       " 'border_count': 64}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_params_after_tuning = tuning_hyperparams(CatBoostRegressor,\n",
    "                                            X=X,\n",
    "                                            y=y,\n",
    "                                            init_params=cb_init_params,\n",
    "                                            fit_params=сb_fit_params,\n",
    "                                            grid_params=cb_grid_params,\n",
    "                                            n_iter=20\n",
    "                                            )\n",
    "cb_params_after_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Training algorithm is CatBoostRegressor=============\n",
      "Fold 0 : Score 10.924275519995549\n",
      "Fold 1 : Score 12.584374819700574\n",
      "Fold 2 : Score 11.57913045597363\n",
      "Mean RSME Score 11.013180769293538\n"
     ]
    }
   ],
   "source": [
    "cb_tuning_score, cb_tuning_model = train_model(CatBoostRegressor,\n",
    "                X,\n",
    "                y,\n",
    "                early_stopping_rounds = 50,\n",
    "                init_params = cb_params_after_tuning,\n",
    "                cat_features = cat_features,\n",
    "                random_seed = 2023\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_cb_test_pred = cb_tuning_model.predict(X_test)\n",
    "pd.DataFrame({'car_id': test['car_id'], 'target_reg': cb_test_pred}).to_csv('tuning_cb_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\n",
    "    'model_name': 'CatBoostRegressor',\n",
    "    'tuning': True,\n",
    "    'kfold_score': cb_tuning_score,\n",
    "    'leaderboard_score': 'RMSE=11.9',\n",
    "    'model': cb_tuning_model\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model', 'car_type', 'fuel_type']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6️⃣ **LightGBMRegressor (goss).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем LabelEncoder для каждой колонки\n",
    "encoders = {}\n",
    "X_lgb = X.copy()\n",
    "\n",
    "# Применяем LabelEncoder к каждой колонке в cat_features\n",
    "for col in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    X_lgb[col] = le.fit_transform(X[col])\n",
    "    encoders[col] = le  \n",
    "\n",
    "X_test_lgb = X_test.copy()\n",
    "for col in cat_features:\n",
    "    le = encoders[col]\n",
    "    X_test_lgb[col] = X_test[col].map(lambda s: le.transform([s])[0] if s in le.classes_ else -1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_init_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_jobs': -1,\n",
    "    'metric': 'RMSE',\n",
    "    'objective': 'regression',\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'verbosity': -1,\n",
    "    'device': 'cpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Training algorithm is LGBMRegressor=============\n",
      "Fold 0 : Score 12.352780364094844\n",
      "Fold 1 : Score 12.345895813022121\n",
      "Fold 2 : Score 11.972325500395383\n",
      "Mean RSME Score 12.045919564864533\n"
     ]
    }
   ],
   "source": [
    "lgb_score, lgb_model = train_model(LGBMRegressor,\n",
    "                                   X_lgb,\n",
    "                                   y,\n",
    "                                   early_stopping_rounds=50,\n",
    "                                   init_params=lgb_init_params,\n",
    "                                   cat_features=cat_features,\n",
    "                                   random_seed=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_test_pred = lgb_model.predict(X_test_lgb)\n",
    "pd.DataFrame({'car_id': test['car_id'], 'target_reg': lgb_test_pred}).to_csv('lgb_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\n",
    "    'model_name': 'LGBMRegressor (goss)',\n",
    "    'tuning': False,\n",
    "    'mean_kfold_score': lgb_score,\n",
    "    'leaderboard_score': 'RMSE=11.9',\n",
    "    'model': lgb_model\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Подбор гиперпараметров и обучение модели с новыми параметрами**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'n_jobs': -1,\n",
       " 'metric': 'RMSE',\n",
       " 'objective': 'regression',\n",
       " 'random_state': 42,\n",
       " 'verbosity': -1,\n",
       " 'device': 'cpu',\n",
       " 'num_leaves': 20,\n",
       " 'n_estimators': 500,\n",
       " 'min_data_in_leaf': 10,\n",
       " 'max_depth': 10,\n",
       " 'learning_rate': 0.01,\n",
       " 'lambda_l2': 1.0,\n",
       " 'lambda_l1': 0.0,\n",
       " 'feature_fraction': 0.8,\n",
       " 'bagging_freq': 5,\n",
       " 'bagging_fraction': 1.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "lgb_fit_params = {\n",
    "    'eval_metric': 'rmse',\n",
    "    'categorical_feature': cat_features\n",
    "}\n",
    "\n",
    "lgb_grid_params = {\n",
    "    'max_depth': [3, 5, 7, 10, -1],           \n",
    "    'min_data_in_leaf': [10, 20, 30, 50],     \n",
    "    'num_leaves': [20, 31, 40, 50],            \n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],   \n",
    "    'feature_fraction': [0.6, 0.8, 1.0],       \n",
    "    'bagging_fraction': [0.6, 0.8, 1.0],      \n",
    "    'bagging_freq': [0, 5, 10],               \n",
    "    'lambda_l1': [0.0, 0.1, 1.0],              \n",
    "    'lambda_l2': [0.0, 0.1, 1.0],              \n",
    "    'boosting_type': ['gbdt', 'dart'],         \n",
    "    'n_estimators': [100, 200, 500]            \n",
    "}\n",
    "\n",
    "lgb_params_after_tuning = tuning_hyperparams(\n",
    "    algorithm=LGBMRegressor,\n",
    "    X=X_lgb,\n",
    "    y=y,\n",
    "    init_params=lgb_init_params,\n",
    "    grid_params=lgb_grid_params,\n",
    "    fit_params=lgb_fit_params,\n",
    "    n_iter=50,\n",
    "    cv=5\n",
    ")\n",
    "lgb_params_after_tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Training algorithm is LGBMRegressor=============\n",
      "Fold 0 : Score 12.11997131214823\n",
      "Fold 1 : Score 11.924731240074463\n",
      "Fold 2 : Score 11.46437582241237\n",
      "Mean RSME Score 11.561515817314175\n"
     ]
    }
   ],
   "source": [
    "lgb_tuning_score, lgb_tuning_model = train_model(\n",
    "    algorithm=LGBMRegressor,\n",
    "    X=X_lgb, y=y,\n",
    "    init_params=lgb_params_after_tuning,\n",
    "    early_stopping_rounds=50,\n",
    "    cat_features=cat_features,\n",
    "    random_seed=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_tuning_test_pred = lgb_tuning_model.predict(X_test_lgb)\n",
    "pd.DataFrame({'car_id': test['car_id'], 'target_reg': lgb_test_pred}).to_csv('lgb_tuning_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7️⃣ **XGBoostRegressor (dart).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = {}\n",
    "X_xgb = X.copy()\n",
    "\n",
    "# Применяем LabelEncoder к каждой колонке в cat_features\n",
    "for col in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    X_xgb[col] = le.fit_transform(X_xgb[col])\n",
    "    encoders[col] = le  \n",
    "\n",
    "X_test_xgb = X_test.copy()\n",
    "for col in cat_features:\n",
    "    le = encoders[col]\n",
    "    X_test_xgb[col] = X_test_xgb[col].map(lambda s: le.transform([s])[0] if s in le.classes_ else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Training algorithm is XGBRegressor=============\n",
      "Fold 0 : Score 12.321854625996112\n",
      "Fold 1 : Score 12.343150719988948\n",
      "Fold 2 : Score 11.681670723608326\n",
      "Mean RSME Score 11.808630406871782\n"
     ]
    }
   ],
   "source": [
    "xgb_init_params = {\n",
    "    'enable_categorical': True,          \n",
    "    'booster': 'dart',                   \n",
    "    'objective': 'reg:squarederror',     \n",
    "    'eval_metric': 'rmse',               \n",
    "    'random_state': RANDOM_STATE,        \n",
    "    'n_jobs': -1,                        \n",
    "    'verbosity': 0,                      \n",
    "\n",
    "    \n",
    "    'rate_drop': 0.1,                   \n",
    "    'skip_drop': 0.5,                    \n",
    "}\n",
    "\n",
    "\n",
    "xgb_score, xgb_model = train_model(\n",
    "    algorithm=XGBRegressor,\n",
    "    X=X_xgb, y=y,\n",
    "    init_params=xgb_init_params,\n",
    "    early_stopping_rounds=50,\n",
    "    cat_features=cat_features,\n",
    "    random_seed=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_test_pred = xgb_model.predict(DMatrix(X_test_xgb))\n",
    "\n",
    "pd.DataFrame({'car_id': test['car_id'], 'target_reg': xgb_test_pred}).to_csv('xgb_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\n",
    "    'model_name': 'XGBRegressor (dart)',\n",
    "    'tuning': False,\n",
    "    'mean_kfold_score': xgb_score,\n",
    "    'leaderboard_score': 'RMSE 12.2',\n",
    "    'model': xgb_model\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Подбор гиперпараметров и обучение модели с новыми параметрами**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enable_categorical': True,\n",
       " 'booster': 'dart',\n",
       " 'objective': 'reg:squarederror',\n",
       " 'eval_metric': 'rmse',\n",
       " 'random_state': 42,\n",
       " 'n_jobs': -1,\n",
       " 'verbosity': 0,\n",
       " 'rate_drop': 0.1,\n",
       " 'skip_drop': 0.5,\n",
       " 'subsample': 0.8,\n",
       " 'n_estimators': 300,\n",
       " 'max_leaves': 0,\n",
       " 'max_depth': 5,\n",
       " 'learning_rate': 0.05,\n",
       " 'colsample_bytree': 1.0}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid_params = {\n",
    "    'max_depth': [3, 5, 7, 10],            # Глубина дерева\n",
    "    'max_leaves': [0, 31, 50, 100],        # Максимальное количество листьев\n",
    "    'learning_rate': [0.01, 0.05, 0.1],    # Темп обучения\n",
    "    'n_estimators': [100, 200, 300],       # Количество деревьев\n",
    "    'subsample': [0.8, 0.9, 1.0],          # Доля выборки для каждого дерева\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],   # Доля признаков для каждого дерева\n",
    "}\n",
    "\n",
    "\n",
    "xgb_fit_params = {\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "xgb_params_after_tuning = tuning_hyperparams(algorithm=XGBRegressor,\n",
    "                                             X=X_xgb, y=y,\n",
    "                                             init_params=xgb_init_params,\n",
    "                                             fit_params=xgb_fit_params,\n",
    "                                             grid_params=xgb_grid_params,\n",
    "                                             n_iter=30,\n",
    "                                             cv=5,\n",
    "                                             random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "xgb_params_after_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Training algorithm is XGBRegressor=============\n",
      "Fold 0 : Score 14.235536385595745\n",
      "Fold 1 : Score 15.125368915878502\n",
      "Fold 2 : Score 14.183297274894453\n",
      "Mean RSME Score 14.082423882612263\n"
     ]
    }
   ],
   "source": [
    "xgb_tuning_score, xgb_tuning_model = train_model(\n",
    "    algorithm=XGBRegressor,\n",
    "    X=X_xgb, y=y,\n",
    "    init_params=xgb_params_after_tuning,\n",
    "    early_stopping_rounds=50,\n",
    "    cat_features=cat_features,\n",
    "    random_seed=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_xgb_test_pred = xgb_tuning_model.predict(DMatrix(X_test_xgb))\n",
    "\n",
    "pd.DataFrame({'car_id': test['car_id'], 'target_reg': tuning_xgb_test_pred}).to_csv('tuning_xgb_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\n",
    "    'model_name': 'XGBRegressor (dart)',\n",
    "    'tuning': True,\n",
    "    'mean_kfold_score': xgb_tuning_score,\n",
    "    'leaderboard_score': 'RMSE 14.5',\n",
    "    'model': xgb_tuning_model\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_name': 'CatBoostRegressor',\n",
       "  'tuning': False,\n",
       "  'kfold_score': 11.471524232962208,\n",
       "  'leaderboard_score': 'RMSE=11.9',\n",
       "  'model': <catboost.core.CatBoostRegressor at 0x106c33280>},\n",
       " {'model_name': 'CatBoostRegressor',\n",
       "  'tuning': True,\n",
       "  'kfold_score': 11.013180769293538,\n",
       "  'leaderboard_score': 'RMSE=11.9',\n",
       "  'model': <catboost.core.CatBoostRegressor at 0x106c328c0>},\n",
       " {'model_name': 'LGBMRegressor (goss)',\n",
       "  'tuning': False,\n",
       "  'mean_kfold_score': 12.045919564864533,\n",
       "  'leaderboard_score': 'RMSE=11.9',\n",
       "  'model': <lightgbm.basic.Booster at 0x17613ec20>},\n",
       " {'model_name': 'XGBRegressor (dart)',\n",
       "  'tuning': False,\n",
       "  'mean_kfold_score': 11.808630406871782,\n",
       "  'leaderboard_score': 'RMSE 12.2',\n",
       "  'model': <xgboost.core.Booster at 0x30e91e920>},\n",
       " {'model_name': 'XGBRegressor (dart)',\n",
       "  'tuning': True,\n",
       "  'mean_kfold_score': 14.082423882612263,\n",
       "  'leaderboard_score': 'RMSE 14.5',\n",
       "  'model': <xgboost.core.Booster at 0x30e9e1d20>}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cb_model = cb_model\n",
    "best_cb_model.save_model('best_cb_model.cbm')\n",
    "\n",
    "best_lgb_model = lgb_model\n",
    "best_lgb_model.save_model('best_lgb_model.mod')\n",
    "\n",
    "\n",
    "best_xgb_model = xgb_model\n",
    "best_xgb_model.save_model('best_xgb_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = (cb_model.predict(X_test) + lgb_model.predict(X_test_lgb) + xgb_model.predict(DMatrix(X_test_xgb)))/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45.08659275, 33.12411749, 32.16873894, ..., 35.14593856,\n",
       "       46.32541362, 48.44395433])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'car_id': test['car_id'], 'target_reg': final_pred}).to_csv('final_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
